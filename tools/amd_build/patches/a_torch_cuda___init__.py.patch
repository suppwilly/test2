diff --git a/torch/cuda/__init__.py b/torch/cuda/__init__.py
index 8450f27812..1de27a5b0d 100644
--- a/torch/cuda/__init__.py
+++ b/torch/cuda/__init__.py
@@ -144,8 +144,6 @@ def _lazy_call(callable):
         # Don't store the actual traceback to avoid memory cycle
         _queued_calls.append((callable, traceback.format_stack()))
 
-_lazy_call(_check_capability)
-
 
 class DeferredCudaCallError(Exception):
     pass
@@ -191,9 +189,6 @@ def _lazy_init():
                 "Cannot re-initialize CUDA in forked subprocess. " + msg)
         _check_driver()
         torch._C._cuda_init()
-        _cudart = _load_cudart()
-        _cudart.cudaGetErrorName.restype = ctypes.c_char_p
-        _cudart.cudaGetErrorString.restype = ctypes.c_char_p
         _original_pid = os.getpid()
         # Some of the queued calls may reentrantly call _lazy_init();
         # we need to just return without initializing in that case.
